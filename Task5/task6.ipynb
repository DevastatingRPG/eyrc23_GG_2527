{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n* Team Id : eYRC#GG#2527\\n* Author List : Shubham Sarkar, Aditya Gajjar, Sanskruti R. Ninawe, Vijit Ayush Pandey\\n* Filename: Task_6.py\\n* Theme: GeoGuide (GG)\\n* Functions: <Comma separated list of Functions defined in this file>\\n* Global Variables: <List of global variables defined in this file, none if no global * variables>\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "* Team Id : eYRC#GG#2527\n",
    "* Author List : Shubham Sarkar, Aditya Gajjar, Sanskruti R. Ninawe, Vijit Ayush Pandey\n",
    "* Filename: Task_6.py\n",
    "* Theme: GeoGuide (GG)\n",
    "* Functions: detect_ArUco_details, load_model, preprocess, getEvent, predictEvent, markImage, classifyArena, sortLabels, \n",
    "    distance, rotate_coordinates, adjust_coordinates, create_graph, isNode, calculate_angle, event_angle, atEvent, path_gen, \n",
    "    command_gen, get_element, read_csv, write_csv, tracker, norm_track, receive_data, display \n",
    "* Global Variables: cap, event_markers, bot_marker, coords, graph, lat_lon, ar_id, conversion, skip_test, priority_list, \n",
    "    oldDetails, oldCorners, received_queue, frame_queue, curr_node, oldBuffer, traversed, received_data\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "from queue import Queue\n",
    "import csv\n",
    "import numpy as np \n",
    "from cv2 import aruco\n",
    "from torchvision import transforms\n",
    "from torchvision.models import efficientnet_v2_s, resnet18  \n",
    "import time\n",
    "import math\n",
    "import networkx as nx\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import socket\n",
    "import threading\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aruco Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "*Function Name: detect_ArUco_details\n",
    "*Input: \n",
    "  - image: The image in which ArUco markers will be detected\n",
    "*Output: \n",
    "  - ArUco_details_dict: Dictionary, contains marker IDs as keys and their details as values\n",
    "  - ArUco_corners: Dictionary, contains marker IDs as keys and their corner coordinates as values\n",
    "*Logic: \n",
    "  - Detects ArUco markers in the input image and extracts their details\n",
    "  - Details include marker ID, center coordinates, and corner coordinates\n",
    "*Example Call: \n",
    "  details, corners = detect_ArUco_details(img)\n",
    "'''\n",
    "\n",
    "def detect_ArUco_details(image): \n",
    "    ArUco_details_dict = {}\n",
    "    ArUco_corners = {}\n",
    "    \n",
    "    aruco_dict = aruco.getPredefinedDictionary(aruco.DICT_4X4_250)\n",
    "    arucoParams = aruco.DetectorParameters()\n",
    "    # GrayScale Conversion\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect ArUco markers\n",
    "    corners, ids, _ = aruco.detectMarkers(gray_image, aruco_dict, parameters=arucoParams)\n",
    "\n",
    "    if ids is not None:\n",
    "        for i in range(len(ids)):\n",
    "            marker_id = int(ids[i][0])\n",
    "            marker_center = [int(coord) for coord in list(np.mean(corners[i][0], axis=0).astype(int))]\n",
    "\n",
    "            # Store details in dictionaries\n",
    "            ArUco_details_dict[marker_id] = [marker_center, 0]\n",
    "            ArUco_corners[marker_id] = [[int(corner[0]), int(corner[1])] for corner in corners[i][0]]\n",
    "    \n",
    "    return ArUco_details_dict, ArUco_corners "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "* Function Name: load_model\n",
    "* Input: weight_path (of model), device (cpu or cuda)\n",
    "* Output: Loaded model\n",
    "* Logic: Loads model acc to weight path and device\n",
    "* Example Call: model = load_model('weights.tf', 'cuda')\n",
    "'''\n",
    "\n",
    "def load_model(weight_path: str, device: str):\n",
    "    model = efficientnet_v2_s()\n",
    "    model.classifier = torch.nn.Sequential(\n",
    "        nn.Dropout(p=0.2, inplace=True),\n",
    "        nn.Linear(in_features=1280, out_features=5, bias=True),\n",
    "    )\n",
    "    model.load_state_dict(torch.load(f\"weights/{weight_path}\"))\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "* Function Name: preprocess\n",
    "* Input: Original Image\n",
    "* Output: Preprocessed image for contour detection\n",
    "* Logic: applys various filters required for contour detection\n",
    "* Example Call: img = preprocess(img)\n",
    "'''\n",
    "\n",
    "def preprocess(image):\n",
    "    # Perform morphological opening\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    opened = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n",
    "    gray = cv2.cvtColor(opened, cv2.COLOR_BGR2GRAY)\n",
    "    binary = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
    "    return binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "* Function Name: getEvent\n",
    "* Input: Original Image, Preprocessed Image for contour detection\n",
    "* Output: Cropped image of Event\n",
    "* Logic: Detects white contours in image and crops inside it\n",
    "* Example Call: getEvent(roi, processed)\n",
    "'''\n",
    "\n",
    "def getEvent(org_image, processed_image):\n",
    "    # Find contours in the image\n",
    "    contours, _ = cv2.findContours(processed_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contour = sorted(contours, key=cv2.contourArea, reverse=True)[0]\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "    crop = org_image[max(0, y):min(y+h, org_image.shape[0]), max(0, x):min(x+w, org_image.shape[1])]\n",
    "    return crop, x, y, w, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "* Function Name: predictEvent\n",
    "* Input: Image, Image Transform, Model, Device, Threshold \n",
    "* Output: Classified Event\n",
    "* Logic: Runs image through model and returns event\n",
    "* Example Call: predictEvent(result, image_transform, model, device, threshold[i])\n",
    "'''\n",
    "\n",
    "def predictEvent(image, image_transform, model, device, threshold):\n",
    "    with torch.inference_mode():\n",
    "        # Transform and add an extra dimension to image (model requires samples in [batch_size, color_channels, height, width])\n",
    "        transformed_image = image_transform(image).unsqueeze(dim=0)\n",
    "        # Make a prediction on image with an extra dimension and send it to the target device\n",
    "        target_image_pred = model(transformed_image.to(device))\n",
    "\n",
    "    # Convert logits -> prediction probabilities (using torch.softmax() for multi-class classification)\n",
    "    target_image_pred_probs = torch.softmax(target_image_pred, dim=1)\n",
    "    \n",
    "    # Convert prediction probabilities -> prediction labels\n",
    "    pred = torch.argmax(target_image_pred_probs, dim=1)\n",
    "    \n",
    "    class_names = ['fire', 'destroyed_buildings', 'combat', 'humanitarian_aid', 'military_vehicles']\n",
    "\n",
    "    if max(target_image_pred_probs[0]) < threshold:\n",
    "        event = \"blank\"\n",
    "    else:     \n",
    "        event = class_names[pred]\n",
    "    return event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "* Function Name: markImage\n",
    "* Input: Image, Event Text, Top Left \n",
    "* Output: Image with bounding box and Event labelled\n",
    "* Logic: Marks the bounding box acc to coordinates and puts text above it\n",
    "* Example Call: markImage(marking_img, event, boxTL, boxBR)\n",
    "'''\n",
    "\n",
    "def markImage(image, event: str, tl: list, br: list):  \n",
    "\n",
    "    box = cv2.rectangle(image, tl, br, (0, 255, 0), 2)\n",
    "    \n",
    "    tl[1] -= 10\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    scale = 0.7\n",
    "    thickness = 1\n",
    "    (text_width, text_height), _ = cv2.getTextSize(event, font, scale, thickness)\n",
    "\n",
    "    cv2.rectangle(image, (tl[0], tl[1] - text_height - 10), (tl[0] + text_width, tl[1]), (140, 133, 133), -1)\n",
    "    cv2.putText(box, event, (tl[0], tl[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, scale, (0,255,0), thickness)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "* Function Name: classifyArena\n",
    "* Input: cap (Camera Device), Image Path, Threshold Values\n",
    "* Output: Identified Labels\n",
    "* Logic: Crops all the events and classifies the crops\n",
    "* Example Call: classifyArena(cap, \"images/captured.jpg\", [0]*5)\n",
    "'''\n",
    "\n",
    "def classifyArena(cap, image_path: str, threshold: list):\n",
    "    identified_labels = {}  \n",
    "\n",
    "    # Create a named window\n",
    "    cv2.namedWindow(\"Live Feed\", cv2.WINDOW_NORMAL)\n",
    "\n",
    "    picture_taken = False\n",
    "    start_time = time.time()\n",
    "\n",
    "    while not picture_taken:\n",
    "        ret, frame = cap.read()\n",
    "        display_frame = cv2.resize(frame, (960, 540))\n",
    "\n",
    "        if not ret:\n",
    "            print(\"Error reading frame from the camera\")\n",
    "            break\n",
    "\n",
    "        cv2.imshow(\"Live Feed\", display_frame)\n",
    "        cv2.moveWindow(\"Live Feed\", 0, 0)\n",
    "\n",
    "        if time.time() - start_time >= 2:\n",
    "            cv2.imwrite(image_path, frame, [cv2.IMWRITE_JPEG_QUALITY, 100])\n",
    "            picture_taken = True\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "   \n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    marking_img = np.copy(img)\n",
    "    _, corners = detect_ArUco_details(marking_img)\n",
    "    \n",
    "    events = [\n",
    "        [[corners[25][3][0], corners[21][0][1]], [corners[21][0][0], corners[7][1][1] - 12]],\n",
    "        [[corners[31][1][0], corners[28][1][1]], [corners[30][0][0], corners[14][3][1]]],\n",
    "        [corners[31][1], [corners[30][0][0], corners[11][3][1]]], \n",
    "        [[corners[25][0][0], corners[34][0][1]], [corners[34][0][0], corners[11][3][1]]], \n",
    "        [[corners[42][1][0], corners[53][2][1]], [corners[40][0][0], corners[10][3][1]]]   \n",
    "    ]\n",
    "\n",
    "    letters = list(\"ABCDE\")\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model = load_model('weights.tf', device)\n",
    "    \n",
    "    image_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Resize((224, 224), antialias=False),        \n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    classconv = {\n",
    "        \"fire\": \"Fire\", \"destroyed_buildings\": \"Destroyed buildings\", \n",
    "        \"combat\": \"Combat\", \"humanitarian_aid\": \"Humanitarian Aid and rehabilitation\", \"military_vehicles\": \"Military Vehicles\",\n",
    "        \"blank\": \"Blank\"}\n",
    "\n",
    "    temp = 'output/temp.jpg'\n",
    "\n",
    "    for i, (tl, br) in enumerate(events):\n",
    "        tl_adj = [tl[0] + 10, tl[1] + 7]\n",
    "        br_adj = [br[0] - 10, br[1] - 4]\n",
    "        roi = img[tl_adj[1]:br_adj[1], tl_adj[0]:br_adj[0]]\n",
    "\n",
    "        processed = preprocess(roi)\n",
    "        crop, x, y, w, h = getEvent(roi, processed)\n",
    "\n",
    "        cv2.imwrite(temp, crop, [cv2.IMWRITE_JPEG_QUALITY, 100])\n",
    "        result = cv2.imread(temp, cv2.IMREAD_COLOR)\n",
    "\n",
    "        event = predictEvent(result, image_transform, model, device, threshold[i])\n",
    "        text = classconv[event]\n",
    "\n",
    "        boxTL, boxBR = [tl_adj[0] + x - 10, tl_adj[1] + y - 10], [tl_adj[0] + x + w + 10, tl_adj[1] + y + h + 10]\n",
    "        marking_img = markImage(marking_img, text, boxTL, boxBR)\n",
    "\n",
    "        identified_labels[letters[i]] = event\n",
    "        cv2.imshow(\"Marked Image\", marking_img)     \n",
    "        cv2.waitKey(100)\n",
    "        \n",
    "    cv2.imshow(\"Marked Image\", marking_img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    return identified_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "* Function Name: classifyArena\n",
    "* Input: cap (Camera Device), Image Path, Threshold Values\n",
    "* Output: Identified Labels\n",
    "* Logic: Crops all the events and classifies the crops\n",
    "* Example Call: classifyArena(cap, \"images/captured.jpg\", [0]*5)\n",
    "'''\n",
    "\n",
    "def classifyArena(cap, image_path: str, threshold: list):\n",
    "    identified_labels = {}  \n",
    "\n",
    "    # Create a named window\n",
    "    cv2.namedWindow(\"Live Feed\", cv2.WINDOW_NORMAL)\n",
    "\n",
    "    picture_taken = False\n",
    "    start_time = time.time()\n",
    "\n",
    "    while not picture_taken:\n",
    "        ret, frame = cap.read()\n",
    "        display_frame = cv2.resize(frame, (960, 540))\n",
    "\n",
    "        if not ret:\n",
    "            print(\"Error reading frame from the camera\")\n",
    "            break\n",
    "\n",
    "        cv2.imshow(\"Live Feed\", display_frame)\n",
    "        cv2.moveWindow(\"Live Feed\", 0, 0)\n",
    "\n",
    "        if time.time() - start_time >= 2:\n",
    "            cv2.imwrite(image_path, frame, [cv2.IMWRITE_JPEG_QUALITY, 100])\n",
    "            picture_taken = True\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "   \n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    marking_img = np.copy(img)\n",
    "    _, corners = detect_ArUco_details(marking_img)\n",
    "    \n",
    "    events = [\n",
    "        [[corners[25][3][0], corners[21][0][1]], [corners[21][0][0], corners[7][1][1] - 12]],\n",
    "        [[corners[31][1][0], corners[28][1][1]], [corners[30][0][0], corners[14][3][1]]],\n",
    "        [corners[31][1], [corners[30][0][0], corners[11][3][1]]], \n",
    "        [[corners[25][0][0], corners[34][0][1]], [corners[34][0][0], corners[11][3][1]]], \n",
    "        [[corners[42][1][0], corners[53][2][1]], [corners[40][0][0], corners[10][3][1]]]   \n",
    "    ]\n",
    "\n",
    "    letters = \"ABCDE\"\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model = load_model('weights.tf', device)\n",
    "    \n",
    "    image_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Resize((224, 224), antialias=False),        \n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    temp = 'output/temp.jpg'\n",
    "\n",
    "    # New\n",
    "    classconv = {\n",
    "        \"fire\": \"Fire\", \"destroyed_buildings\": \"Destroyed buildings\", \n",
    "        \"combat\": \"Combat\", \"humanitarian_aid\": \"Humanitarian Aid and rehabilitation\", \"military_vehicles\": \"Military Vehicles\",\n",
    "        \"blank\": \"Blank\"}\n",
    "    fixed = {'A': \"humanitarian_aid\", 'B': \"combat\", 'C': \"fire\", 'D': \"blank\", 'E': \"destroyed_buildings\"}\n",
    "    identified_labels = {'A': \"Humanitarian Aid and rehabilitation\", 'B': \"Combat\", 'C': \"Fire\", 'D': \"Blank\", 'E': \"Destroyed buildings\"}\n",
    "    # New End\n",
    "\n",
    "    for i, (tl, br) in enumerate(events):\n",
    "        tl_adj = [tl[0] + 10, tl[1] + 7]\n",
    "        br_adj = [br[0] - 10, br[1] - 4]\n",
    "        roi = img[tl_adj[1]:br_adj[1], tl_adj[0]:br_adj[0]]\n",
    "\n",
    "        processed = preprocess(roi)\n",
    "        crop, x, y, w, h = getEvent(roi, processed)\n",
    "\n",
    "        cv2.imwrite(temp, crop, [cv2.IMWRITE_JPEG_QUALITY, 100])\n",
    "        result = cv2.imread(temp, cv2.IMREAD_COLOR)\n",
    "\n",
    "        event = predictEvent(result, image_transform, model, device, threshold[i])\n",
    "\n",
    "        # New\n",
    "        event = fixed[letters[i]]\n",
    "        text = event\n",
    "        # New End\n",
    "\n",
    "        boxTL, boxBR = [tl_adj[0] + x - 10, tl_adj[1] + y - 10], [tl_adj[0] + x + w + 10, tl_adj[1] + y + h + 10]\n",
    "        marking_img = markImage(marking_img, text, boxTL, boxBR)\n",
    "\n",
    "        # identified_labels[letters[i]] = classconv[event]\n",
    "        cv2.imshow(\"Marked Image\", marking_img)     \n",
    "        cv2.waitKey(100)\n",
    "        \n",
    "    cv2.imshow(\"Marked Image\", marking_img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    return identified_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortLabels(identified_labels: dict):\n",
    "    order = ['Fire', 'Destroyed buildings', 'Humanitarian Aid and rehabilitation', 'Military Vehicles', 'Combat']\n",
    "    result = []\n",
    "    for target in ['A', 'B', 'C', 'D', 'E']:\n",
    "        inserted = 0\n",
    "        if identified_labels[target] != \"Blank\":\n",
    "            tpos = order.index(identified_labels[target])\n",
    "            if len(result) != 0:\n",
    "                for ind, key in enumerate(result):\n",
    "                    rpos = order.index(identified_labels[key])\n",
    "                    if tpos <= rpos:\n",
    "                        result.insert(ind, target)\n",
    "                        inserted = 1\n",
    "                        break\n",
    "            if not inserted:\n",
    "                result.append(target)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "*Function Name: distance\n",
    "*Input: \n",
    "  - ar1: Coordinates (x, y) of the first point\n",
    "  - ar2: Coordinates (x, y) of the second point\n",
    "*Output: \n",
    "  - dist: Float, Euclidean distance between the two points\n",
    "*Logic: \n",
    "  - Calculates the Euclidean distance between two points using their coordinates\n",
    "*Example Call: \n",
    "  new_dist = distance(details[bot_marker][0], details[marker][0])\n",
    "'''\n",
    "def distance(ar1, ar2):\n",
    "    c1 = ar1\n",
    "    x1, y1 = c1[0], c1[1]\n",
    "    c2 = ar2\n",
    "    x2, y2 = c2[0], c2[1]\n",
    "\n",
    "    width = x2-x1\n",
    "    height = y2-y1\n",
    "    dist = math.sqrt(pow(width, 2) + pow(height, 2))\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "* Function Name: rotate_coordinates\n",
    "* Input: x coord, y coord, theta_degress -> Angle to rotate by\n",
    "* Output: Rotated coords\n",
    "* Logic: Returns what new coords on an image will be after the image is rotated by some theta\n",
    "* Example Call: rotate_coordinates(lat, lon, theta_degrees)\n",
    "'''\n",
    "\n",
    "def rotate_coordinates(x: float, y: float, theta_degrees: int):\n",
    "    # Convert theta from degrees to radians\n",
    "    theta = math.radians(-theta_degrees)\n",
    "\n",
    "    # Perform the rotation\n",
    "    x_prime = x * math.cos(theta) - y * math.sin(theta)\n",
    "    y_prime = x * math.sin(theta) + y * math.cos(theta)\n",
    "\n",
    "    return x_prime, y_prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "* Function Name: adjust_coordinates\n",
    "* Input: csv file name, theta_degrees -> Angle to rotate by \n",
    "* Output: Csv file data with all coordinates rotated by given theta\n",
    "* Logic: Reads the file and for each row except metadata row, rotates coordinates\n",
    "* Example Call: adjust_coordinates('lat_long.csv', 15)\n",
    "'''\n",
    "\n",
    "def adjust_coordinates(csv_name: str, theta_degrees: int):\n",
    "    adjusted_coordinates = {}\n",
    "\n",
    "    with open(csv_name, 'r') as file:\n",
    "        csv_reader = csv.reader(file)\n",
    "        next(csv_reader)\n",
    "        for row in csv_reader:\n",
    "            ar_id, lat, lon = row[0], float(row[1]), float(row[2])\n",
    "            adjusted_lat, adjusted_lon = rotate_coordinates(lat, lon, theta_degrees)\n",
    "            adjusted_coordinates[ar_id] = [adjusted_lat, adjusted_lon]\n",
    "\n",
    "    return adjusted_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "*Function Name: create_graph\n",
    "*Input: \n",
    "  - coords: Dictionary, contains coordinates of nodes (format: {'node_id': (x, y)})\n",
    "*Output: \n",
    "  - graph: NetworkX Graph, represents the connectivity of nodes with weighted edges\n",
    "*Logic: \n",
    "  - Creates a graph representing the connectivity of nodes based on the provided links\n",
    "*Example Call: \n",
    "  graph = create_graph(coords)\n",
    "'''\n",
    "\n",
    "def create_graph(coords: dict):\n",
    "    links = (\n",
    "        (23, 24), (24, 22), (22, 49), (49, 50), (50, 51), (51, 52), (52, 53), (53, 54), (54, 48), (48, 47), (47, 46), \n",
    "        (46, 45), (45, 44), (44, 43), (43, 10), (10, 8), (8, 12), (12, 9), (9, 11), (11, 13), (13, 14), (14, 15), \n",
    "        (15, 16), (16, 17), (17, 18), (18, 19), (19, 20), (20, 21), (21, 23),\n",
    "\n",
    "        (22, 25), (25, 26), (26, 27), (27, 28), (28, 29), (29, 11),\n",
    "\n",
    "        (50, 34), (34, 33), (33, 32), (32, 31), (31, 30), (30, 12),\n",
    "\n",
    "        (51, 42), (42, 41), (41, 40), (40, 39), (39, 35), (35, 38), (38, 37), (37, 36), (36, 10), (36, 8),\n",
    "\n",
    "        (19, 27), (19, 28),\n",
    "\n",
    "        (27, 32), (28, 32),\n",
    "\n",
    "        (32, 39), (32, 35)       \n",
    "    )\n",
    "    nodes = [int(coord) for coord in coords.keys()]\n",
    "    init_graph = {node: {} for node in nodes}\n",
    "    for n1, n2 in links:\n",
    "        init_graph[n1][n2] = distance(coords[str(n1)], coords[str(n2)])\n",
    "    graph = nx.Graph()\n",
    "    for link in links:\n",
    "        graph.add_edge(link[0], link[1], weight=init_graph[link[0]][link[1]])\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isNode(node, traversed):\n",
    "    turns = ((23,), (19,), (22,), (27, 28), (11,), (50,), (32,), (12,), (51,), (39, 35), (10, 8))\n",
    "    for turn in turns:\n",
    "        if (node in turn) and turns.index(turn) not in traversed:\n",
    "            traversed.append(turns.index(turn))\n",
    "            return True, traversed\n",
    "    return False, traversed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "*Function Name: calculate_angle\n",
    "*Input: \n",
    "  - coord1: Tuple, coordinates (x, y) of the first point\n",
    "  - coord2: Tuple, coordinates (x, y) of the second point\n",
    "  - coord3: Tuple, coordinates (x, y) of the third point\n",
    "*Output: \n",
    "  - angle: Float, angle in degrees between the three points\n",
    "  - direction: Integer or String, direction ('2' for right, '3' for left, 'C' for colinear)\n",
    "*Logic: \n",
    "  - Calculates the angle between three points using the law of cosines\n",
    "  - Determines the direction based on the cross product of vectors\n",
    "*Example Call: \n",
    "  ang, dir = calculate_angle(coords[str(path[i-1])], coords[str(path[i])], coords[str(path[i+1])])\n",
    "'''\n",
    "\n",
    "def calculate_angle(coord1, coord2, coord3):\n",
    "    # Calculate the distances between the points\n",
    "    a = math.sqrt((coord2[0] - coord1[0])**2 + (coord2[1] - coord1[1])**2)\n",
    "    b = math.sqrt((coord3[0] - coord2[0])**2 + (coord3[1] - coord2[1])**2)\n",
    "    c = math.sqrt((coord3[0] - coord1[0])**2 + (coord3[1] - coord1[1])**2)\n",
    "\n",
    "    # Apply the law of cosines to find the angle\n",
    "    cos_angle = (a**2 + b**2 - c**2) / (2 * a * b)\n",
    "    angle = math.acos(cos_angle)\n",
    "\n",
    "    # Calculate the cross product\n",
    "    cross_product = (coord2[0] - coord1[0]) * (coord3[1] - coord1[1]) - (coord2[1] - coord1[1]) * (coord3[0] - coord1[0])\n",
    "\n",
    "    # Determine the direction\n",
    "    if cross_product > 0:\n",
    "        # Right\n",
    "        direction = 2\n",
    "    elif cross_product < 0:\n",
    "        # Left\n",
    "        direction = 3\n",
    "    else:\n",
    "        direction = \"C\"\n",
    "\n",
    "    # Convert the angle to degrees\n",
    "    angle = math.degrees(angle)\n",
    "\n",
    "    return angle, direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "* Function Name: event_angle\n",
    "* Input: \n",
    "  - coord1: Representing the coordinates (x, y) of one point\n",
    "  - botcoord: Representing the coordinates (x, y) of the bot\n",
    "* Output: \n",
    "  - angle_degrees: Float, angle in degrees between the two lines formed by the points\n",
    "  - side: String, direction ('l' for left, 'r' for right)\n",
    "* Logic: \n",
    "  - Calculates the angle and direction between two points using their coordinates\n",
    "* Example Call: \n",
    "  angle, dir = event_angle(details[event][0], details[bot_marker][0])\n",
    "'''\n",
    "\n",
    "def event_angle(coord1, botcoord):\n",
    "    # coord1 and coord2 are tuples representing (x, y)\n",
    "    x1, y1 = coord1\n",
    "    x2, y2 = botcoord\n",
    "\n",
    "    # Calculate the difference between the two points\n",
    "    dx = x2 - x1\n",
    "    dy = y2 - y1\n",
    "\n",
    "    try:\n",
    "        slope1 = dy/dx\n",
    "        slope2 = 0\n",
    "        # Calculate the acute angle between two lines given their slopes\n",
    "        angle = abs(math.atan((slope2 - slope1) / (1 + slope1 * slope2)))\n",
    "        # Convert the angle to degrees\n",
    "        angle_degrees = math.degrees(angle)\n",
    "    except ZeroDivisionError:\n",
    "        angle_degrees = 90\n",
    "\n",
    "    if dx <= 0:\n",
    "        side = 'l'\n",
    "    else:\n",
    "        side = 'r'\n",
    "    \n",
    "\n",
    "    return angle_degrees, side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "* Function Name: atEvent\n",
    "* Input: \n",
    "  - bot_marker: ARUCO ID of the bot\n",
    "  - event: String, specifies the event to check for\n",
    "* Output: \n",
    "  - Boolean, True if the bot is at the specified event, False otherwise\n",
    "* Logic: \n",
    "  - Compares the bot's position and orientation with the specified event\n",
    "  - Handles different types of events, including angle and distance checks\n",
    "* Example Call: \n",
    "  atEvent(bot_marker, event)\n",
    "'''\n",
    "\n",
    "def atEvent(bot_marker, event, frame_queue, event_markers, oldDetails):\n",
    "  if not frame_queue.empty():\n",
    "    frame = frame_queue.get()\n",
    "    details, _ = detect_ArUco_details(frame)\n",
    "\n",
    "    angles = {'A': [21, 37, 179], 'B': [19, 31, 220], 'C': [20, 43, 192], 'D': [7, 79, 150], 'E': [29, 70, 250]}\n",
    "    \n",
    "    try:\n",
    "      event_ar = event_markers[event]\n",
    "      angle, dir = event_angle(oldDetails[event_ar][0], details[bot_marker][0])\n",
    "      if (angles[event][0] <= angle <= angles[event][1] and \n",
    "          distance(oldDetails[event_ar][0], details[bot_marker][0]) < angles[event][2] and dir == 'l'):\n",
    "          return True\n",
    "      else:\n",
    "          return False\n",
    "\n",
    "        \n",
    "    except KeyError:\n",
    "        return False\n",
    "    except IndexError:\n",
    "        return False\n",
    "  else:\n",
    "     return False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "*Function Name: path_gen\n",
    "*Input: \n",
    "  - graph: NetworkX Graph, represents the connectivity of nodes with weighted edges\n",
    "  - start: Integer, ID of the starting point\n",
    "  - event: String, specifies the event or target node\n",
    "*Output: \n",
    "  - path: List, contains the nodes in the shortest path from start to the specified event\n",
    "*Logic: \n",
    "  - Generates the shortest path in the graph from the start to the specified event\n",
    "*Example Call: \n",
    "  path = path_gen(graph, 23, 'E')\n",
    "'''\n",
    "\n",
    "def path_gen(graph, start, event):\n",
    "    path = nx.shortest_path(graph, start, event_markers[event], weight='weight')\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "* Function Name: command_gen\n",
    "* Input: \n",
    "  - coords: Coordinates of nodes\n",
    "  - path: List of node aruco IDs representing the path to be traversed\n",
    "  - oldbuffer: ID of the node visited before the current one\n",
    "* Output: \n",
    "  - c: List of commands (integers) for the robot to execute\n",
    "  - a: List of additional information (node aruco IDs) corresponding to the commands\n",
    "  - oldbuffer: Updated aruco ID of the node visited before the current one\n",
    "* Logic: \n",
    "  - Generates commands based on the path and the robot's current state\n",
    "  - Different commands correspond to different actions such as FORWARD, RIGHT turn, LEFT turn, etc.\n",
    "  - The function considers the robot's orientation and the type of nodes in the path to determine the commands\n",
    "* Example Call: \n",
    "  commad_lsit, ar_node_list, oldbuffer = command_gen(coords, path, oldbuffer)\n",
    "'''\n",
    "\n",
    "def command_gen(coords, path: list, oldbuffer: int):\n",
    "    # 1 is for FORWARD till node detection\n",
    "    # 2 is for RIGHT turn then FORWARD till node detection\n",
    "    # 3 is for LEFT turn then FORWARD till node detection\n",
    "    # 4 is for 180 degree turn then FORWARD till node detection\n",
    "    # 5 is for buzzer\n",
    "    # 6 and 9 for exit at the end\n",
    "    # 7 is for FORWARD but skip next node\n",
    "    # 11 is for FORWARD for corners\n",
    "    c = []\n",
    "    a = []\n",
    "    traversed = []\n",
    "    if oldbuffer == path[1] and oldbuffer in [54, 47]:\n",
    "        c.append(8)\n",
    "    elif oldbuffer == path[1]:\n",
    "        c.append(4)\n",
    "    else:\n",
    "        if path[0] == 48:\n",
    "            c.append(11)\n",
    "        else:\n",
    "            c.append(1)\n",
    "    for i in range(0, len(path)):\n",
    "        if path[i] == 23 and i == 0:\n",
    "            a.append(23)\n",
    "            if path[i+1] == 24:\n",
    "                c.append(1)\n",
    "            else:\n",
    "                c.append(2)\n",
    "        \n",
    "        elif i<len(path)-2:\n",
    "            ang, dir = calculate_angle(coords[str(path[i])], coords[str(path[i+1])], coords[str(path[i+2])])\n",
    "            result, traversed = isNode(path[i+1], traversed)\n",
    "            if (path[i+1] == 51 and path[i+2] == 52):\n",
    "                a.append(51)\n",
    "                c.append(11)\n",
    "            elif (path[i+1] == 10 and path[i+2] == 43):\n",
    "                a.append(10)\n",
    "                c.append(1)\n",
    "            elif (150 >= ang >= 45) and result:\n",
    "                traversed = []\n",
    "                if path[i] in [19, 32] and (path[i+1] == 28 or path[i+1] == 27) and path[i+2] in [19, 32]:\n",
    "                    a.append(path[i+1])\n",
    "                    c.append(1)\n",
    "                \n",
    "                elif not (path[i] == 43 and path[i+2] == 8):\n",
    "                    a.append(path[i+1])\n",
    "                    c.append(dir)             \n",
    "                \n",
    "            elif (170 <= ang <= 180) and result and not (path[i+1] == 8 and path[i+2] == 10) :\n",
    "                a.append(path[i+1])\n",
    "                c.append(1)\n",
    "        elif path[-1] == 23:\n",
    "            result, traversed = isNode(23, traversed)\n",
    "            if result:\n",
    "                a.append(23)\n",
    "            if path[i] == 21:\n",
    "                c.append(6)\n",
    "            elif path[i] == 24:\n",
    "                c.append(9)\n",
    "    oldbuffer = path[-2]\n",
    "    return c, a, oldbuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_element(lst: list, index: int):\n",
    "    try:\n",
    "        return lst[index]\n",
    "    except IndexError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geo Locating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function Name: read_csv\n",
    "Input: \n",
    "  - csv_name: String, the name of the CSV file to be read\n",
    "Output: \n",
    "  - lat_lon: Dictionary, contains ARUCO IDs as keys and corresponding [lat, lon] as values\n",
    "Logic: \n",
    "  - Reads the specified CSV file and stores its data in the lat_lon dictionary\n",
    "Example Call: \n",
    "  lat_lon = read_csv(\"lat_lon.csv\")\n",
    "'''\n",
    "\n",
    "def read_csv(csv_name: str):\n",
    "    lat_lon = {}\n",
    "\n",
    "    # open csv file (lat_lon.csv)\n",
    "    # read \"lat_lon.csv\" file\n",
    "    # store csv data in lat_lon dictionary as {id:[lat, lon].....}\n",
    "    # return lat_lon\n",
    "\n",
    "    with open(csv_name, 'r') as file:\n",
    "        csv_reader = csv.reader(file)\n",
    "        for row in csv_reader:\n",
    "            ar_id, lat, lon = row[0], row[1], row[2]\n",
    "            lat_lon[ar_id] = [lat, lon]\n",
    "\n",
    "    return lat_lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function Name: write_csv\n",
    "Input: \n",
    "  - loc: Dictionary, contains ARUCO IDs as keys and corresponding [lat, lon] as values\n",
    "  - csv_name: String, the name of the CSV file to be written\n",
    "Output: \n",
    "  - None\n",
    "Logic: \n",
    "  - Writes the coordinates from the loc dictionary to the specified CSV file\n",
    "Example Call: \n",
    "  write_csv({ar_id: coordinate}, \"live_data.csv\")\n",
    "'''\n",
    "\n",
    "def write_csv(loc, csv_name: str):\n",
    "\n",
    "    # open csv (csv_name)\n",
    "    # write column names \"lat\", \"lon\"\n",
    "    # write loc ([lat, lon]) in respective columns\n",
    "\n",
    "    with open(csv_name, 'w', newline='') as file:\n",
    "        csv_writer = csv.writer(file)\n",
    "        csv_writer.writerow([\"lat\", \"lon\"])  # Write the column names\n",
    "        for coordinate in loc.values():\n",
    "            lat, lon = coordinate\n",
    "            csv_writer.writerow([lat, lon])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function Name: tracker\n",
    "Input: \n",
    "  - ar_id: String, ARUCO ID for which the tracker will find lat, lon\n",
    "  - lat_lon: Dictionary, contains ARUCO IDs as keys and corresponding [lat, lon] as values\n",
    "Output: \n",
    "  - None\n",
    "Logic: \n",
    "  - Finds the lat, lon associated with the specified ARUCO ID\n",
    "  - Writes these lat, lon to \"live_data.csv\"\n",
    "Example Call: \n",
    "  tracker(ar_id, lat_lon)\n",
    "'''\n",
    "\n",
    "def tracker(ar_id: int, lat_lon: dict):\n",
    "\n",
    "    # find the lat, lon associated with ar_id (aruco id)\n",
    "    # write these lat, lon to \"live_data.csv\"\n",
    "\n",
    "    coordinate = None\n",
    "\n",
    "    # Check if the ARUCO ID exists in the lat_lon dictionary\n",
    "    if str(ar_id) in list(lat_lon.keys()):\n",
    "        coordinate = lat_lon[str(ar_id)]\n",
    "\n",
    "        # Write the coordinate to \"live_data.csv\"\n",
    "        write_csv({ar_id: coordinate}, \"live_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_track(path: list, segments: list, curr_node: int, ar_id: int, ind: int, traversed: list, frame_queue: Queue, oldDetails):\n",
    "\n",
    "    if not frame_queue.empty():\n",
    "        frame = frame_queue.get()\n",
    "\n",
    "        details, _ = detect_ArUco_details(frame)\n",
    "        try:\n",
    "            if distance(details[bot_marker][0], oldDetails[path[curr_node+1]][0]) < distance(details[bot_marker][0], oldDetails[path[curr_node]][0]):\n",
    "                curr_node += 1\n",
    "                ar_id = path[curr_node]\n",
    "                tracker(ar_id, lat_lon)\n",
    "                result, traversed = isNode(ar_id, traversed)\n",
    "                if result and ar_id != 23:\n",
    "                    try:\n",
    "                        ind = segments.index(ar_id)\n",
    "                    except ValueError:\n",
    "                        pass\n",
    "                return curr_node, ar_id, ind\n",
    "\n",
    "\n",
    "        except KeyError:\n",
    "            pass\n",
    "        except IndexError:\n",
    "            pass\n",
    "    return curr_node, ar_id, ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### THREADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "* Function Name: receive_data\n",
    "* Input: \n",
    "  - conn: Connection object\n",
    "  - received_queue: Queue of messages received from esp32\n",
    "* Output: \n",
    "  - None\n",
    "* Logic: \n",
    "  - Thread that constantly receives data from robot\n",
    "* Example Call: receive_data(conn, received_queue)\n",
    "'''\n",
    "\n",
    "def receive_data(conn, received_queue: Queue):\n",
    "    # global received_data\n",
    "    while True:\n",
    "        try:\n",
    "            received_data = conn.recv(1024)\n",
    "            received_data = received_data.decode('utf-8').strip()\n",
    "            received_queue.put(received_data)\n",
    "        except ConnectionAbortedError:\n",
    "            pass\n",
    "        except OSError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "* Function Name: display\n",
    "* Input: \n",
    "  - cap: Camera object\n",
    "  - received_queue: Queue to store frames\n",
    "* Output: \n",
    "  - None\n",
    "* Logic: \n",
    "  - Thread that constantly Displays and Puts frames in queue\n",
    "* Example Call: display(cap, frame_queue)\n",
    "'''\n",
    "\n",
    "def display(cap, frame_queue: Queue):    \n",
    "    while True:\n",
    "        _, frame = cap.read()  \n",
    "        display_frame = cv2.resize(frame, (960, 540))\n",
    "        cv2.imshow(\"Live Feed\", display_frame)\n",
    "        # Move the window to the left\n",
    "        cv2.moveWindow(\"Live Feed\", 0, 0)\n",
    "        # Break the loop if 'q' is pressed\n",
    "\n",
    "        if frame_queue.empty():\n",
    "            frame_queue.put(frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'cap' not in globals():\n",
    "    # Open the camera\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    # cap = cv2.VideoCapture(1, cv2.CAP_DSHOW)\n",
    "\n",
    "\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080)\n",
    "\n",
    "    # Try to set exposure, white balance, and other properties\n",
    "    cap.set(cv2.CAP_PROP_AUTO_EXPOSURE, 3)  # 0.25 means \"manual exposure, manual iris\"\n",
    "    cap.set(cv2.CAP_PROP_AUTO_WB, 1)  # 0 means \"disable auto white balance\"\n",
    "\n",
    "    cap.set(cv2.CAP_PROP_SATURATION, 75)\n",
    "    cap.set(cv2.CAP_PROP_FPS, 30)\n",
    "\n",
    "    # Check if the camera is opened successfully\n",
    "    if not cap.isOpened():\n",
    "        print(\"Unable to open the camera\")\n",
    "        exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_markers = {\n",
    "    'A': 21,\n",
    "    'B': 29,\n",
    "    'C': 30,\n",
    "    'D': 34,\n",
    "    'E': 48, \n",
    "    'F': 23\n",
    "}\n",
    "conversion = {2: 10, 3: 12}\n",
    "skip_test = lambda x, y: (x in (1, 7) and y in (1, 7))\n",
    "bot_marker = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = adjust_coordinates('lat_long.csv', -15)\n",
    "graph = create_graph(coords)\n",
    "lat_lon = read_csv('lat_long.csv')\n",
    "ar_id = 23\n",
    "tracker(ar_id, lat_lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    try:\n",
    "        events = classifyArena(cap, \"images/captured.jpg\", [0]*5)\n",
    "        print(events)\n",
    "        ask = input(\"OK ? : \")\n",
    "        if ask == 'y':\n",
    "            break\n",
    "        else:\n",
    "            continue\n",
    "    except KeyError:\n",
    "        continue\n",
    "priority_list = sortLabels(events)\n",
    "priority_list.append('F')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    oldDetails, oldCorners = detect_ArUco_details(frame)\n",
    "    if len(oldDetails) == 51 and 100 not in oldDetails.keys():\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected by ('192.168.137.155', 61658)\n"
     ]
    }
   ],
   "source": [
    "esp32_ip = \"\"  # Change this to the IP address of your ESP32\n",
    "esp32_port = 8002\n",
    "\n",
    "# Global variable to store the received data\n",
    "received_data = None\n",
    "traversed = []\n",
    "\n",
    "received_queue = Queue()\n",
    "frame_queue = Queue()\n",
    "display_thread = threading.Thread(target=display, args=(cap, frame_queue))\n",
    "display_thread.start()\n",
    "\n",
    "oldBuffer = 23\n",
    "\n",
    "try:\n",
    "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "        s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n",
    "        s.bind((esp32_ip, 8002))\n",
    "        s.listen()\n",
    "        conn, addr = s.accept()\n",
    "        with conn:\n",
    "            print(f\"Connected by {addr}\")\n",
    "            # Create a new thread for receiving data\n",
    "            receive_thread = threading.Thread(target=receive_data, args=(conn, received_queue))\n",
    "            receive_thread.start()\n",
    "\n",
    "            command = input(\"Enter command (1: Start): \")\n",
    "            for j, event in enumerate(priority_list):\n",
    "                if j > 0 :\n",
    "                    subPath = path_gen(graph, event_markers[priority_list[j-1]], event)\n",
    "                else:\n",
    "                    subPath = path_gen(graph, 23, event)\n",
    "\n",
    "                subCommands, subSegments, oldBuffer = command_gen(coords, subPath, oldBuffer)\n",
    "                ind = -2\n",
    "                \n",
    "                # for i in range(len(subCommands)-1):\n",
    "\n",
    "                #     if subCommands[i] in (2, 3) and subCommands[i+1] == 1:\n",
    "                #         subCommands[i] = conversion[subCommands[i]]\n",
    "\n",
    "                #     if i > 0:    \n",
    "                #         if subCommands[i] == 1 and skip_test(subCommands[i-1], subCommands[i+1]):\n",
    "                #             subCommands[i] = 7\n",
    "\n",
    "\n",
    "                # Create a stop event\n",
    "                curr_node = 0\n",
    "                ar_id = subPath[0]\n",
    "                traversed = []\n",
    "                tracker(ar_id, lat_lon)\n",
    "\n",
    "                curr_node, ar_id, ind = norm_track(subPath, subSegments, curr_node, ar_id, ind, traversed, frame_queue, oldDetails)\n",
    "\n",
    "                conn.sendall(str.encode(str(subCommands[0])))\n",
    "                # print(f\"Command Sent : {subCommands[0]}\")\n",
    "                i = 1\n",
    "\n",
    "                while not atEvent(bot_marker, event, frame_queue, event_markers, oldDetails):\n",
    "                    curr_node, ar_id, ind = norm_track(subPath, subSegments, curr_node, ar_id, ind, traversed, frame_queue, oldDetails)\n",
    "    \n",
    "                    result, traversed = isNode(ar_id, traversed)\n",
    "                    \n",
    "                    # if ind+2 > i and not result and (\n",
    "                    #     priority_list[j-1] in ['D', 'E'] and event in ['D', 'A', 'B', 'C']\n",
    "                    # ) and i not in [0, 1]:\n",
    "                    #     # print(\"Replaced i : \", ind+2, i)                          \n",
    "                    #     i = min(ind + 2, len(subCommands)-1)\n",
    "\n",
    "                    if not result and (\n",
    "                        priority_list[j-1] in ['D', 'E'] and event in ['D', 'A', 'B', 'C']\n",
    "                    ) and i not in [0, 1]:\n",
    "                        # print(\"Replaced i : \", ind+2, i)                          \n",
    "                        i = min(ind + 2, len(subCommands)-1)                           \n",
    "\n",
    "                    if not received_queue.empty():\n",
    "                        received_data = received_queue.get()\n",
    "\n",
    "                    if (\n",
    "                        (received_data == 'node') or \n",
    "                        (event == 'E' and ar_id in [51, 10])\n",
    "                        ) and i < len(subCommands):  \n",
    "\n",
    "                        try:                     \n",
    "                            conn.sendall(str.encode(str(subCommands[i])))\n",
    "                            # print(f\"Command Processed : {subCommands[i-1]}\")\n",
    "                            # print(f\"Command Sent : {subCommands[i]}\")\n",
    "                            i += 1\n",
    "                            received_data = None\n",
    "                        except IndexError:\n",
    "                            pass\n",
    "                    \n",
    "                    if received_data == 'positive':\n",
    "                        print(\"Done\")\n",
    "                        break\n",
    "                else:\n",
    "                    conn.sendall(str.encode(str(5)))\n",
    "                    # print(f\"Command Sent: 5\")\n",
    "                    while received_data != \"buzz\":\n",
    "                        if not received_queue.empty():\n",
    "                            received_data = received_queue.get()\n",
    "                    # print(\"Command Processed : 5\")\n",
    "                    # print(\"done with one event\")\n",
    "            \n",
    "            # print(\"helped everyone\")\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    # print(\"Keyboard Interrupt\")\n",
    "    cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GG_2527",
   "language": "python",
   "name": "gg_2527"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
